{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:00:42.050829Z","iopub.status.busy":"2024-05-19T13:00:42.050405Z","iopub.status.idle":"2024-05-19T13:00:42.056458Z","shell.execute_reply":"2024-05-19T13:00:42.055491Z","shell.execute_reply.started":"2024-05-19T13:00:42.050799Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\tanni\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import pandas as pd\n","from datasets import load_dataset, Dataset, DatasetDict\n","from transformers import AutoTokenizer, DataCollatorWithPadding, TrainingArguments, Trainer, AutoModelForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","import torch\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","import os\n","from torch.utils.data import DataLoader\n","from tqdm import trange\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:34.316129Z","iopub.status.busy":"2024-05-19T12:48:34.315315Z","iopub.status.idle":"2024-05-19T12:48:35.868251Z","shell.execute_reply":"2024-05-19T12:48:35.867402Z","shell.execute_reply.started":"2024-05-19T12:48:34.316096Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('./Corrupted Data/total_data_for_corrupt_classif_noBR.csv', index_col=['Unnamed: 0'])\n","df = df.reset_index()\n","df = df.drop(columns=['index'])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:35.890252Z","iopub.status.busy":"2024-05-19T12:48:35.889434Z","iopub.status.idle":"2024-05-19T12:48:35.899514Z","shell.execute_reply":"2024-05-19T12:48:35.898497Z","shell.execute_reply.started":"2024-05-19T12:48:35.890219Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>О человеки все цветов! ― Сказал, зевая, Саваоф...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>В Афинее осторожно Свиток разверня, Весь проч...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Серо-черной, не очень суровой зимою в низкорос...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Всё сохраню, всё пронесу, ― И вечность, что о...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Приятности твои на мысли вображая, В пустынях...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Text  Label\n","0  О человеки все цветов! ― Сказал, зевая, Саваоф...      0\n","1   В Афинее осторожно Свиток разверня, Весь проч...      0\n","2  Серо-черной, не очень суровой зимою в низкорос...      0\n","3   Всё сохраню, всё пронесу, ― И вечность, что о...      0\n","4   Приятности твои на мысли вображая, В пустынях...      0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:38.403890Z","iopub.status.busy":"2024-05-19T12:48:38.403508Z","iopub.status.idle":"2024-05-19T12:48:38.410765Z","shell.execute_reply":"2024-05-19T12:48:38.409793Z","shell.execute_reply.started":"2024-05-19T12:48:38.403862Z"},"trusted":true},"outputs":[],"source":["train_df, val_df = train_test_split(df, test_size=0.15, random_state=22)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:39.764765Z","iopub.status.busy":"2024-05-19T12:48:39.763845Z","iopub.status.idle":"2024-05-19T12:48:39.770224Z","shell.execute_reply":"2024-05-19T12:48:39.769147Z","shell.execute_reply.started":"2024-05-19T12:48:39.764731Z"},"trusted":true},"outputs":[],"source":["train_df = train_df.sample(frac=1)\n","val_df = val_df.sample(frac=1)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:41.146426Z","iopub.status.busy":"2024-05-19T12:48:41.145591Z","iopub.status.idle":"2024-05-19T12:48:41.151580Z","shell.execute_reply":"2024-05-19T12:48:41.150649Z","shell.execute_reply.started":"2024-05-19T12:48:41.146390Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["178075 31425\n"]}],"source":["print(len(train_df), len(val_df))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:42.568164Z","iopub.status.busy":"2024-05-19T12:48:42.567372Z","iopub.status.idle":"2024-05-19T12:48:42.575361Z","shell.execute_reply":"2024-05-19T12:48:42.574387Z","shell.execute_reply.started":"2024-05-19T12:48:42.568129Z"},"trusted":true},"outputs":[{"data":{"text/plain":["88830"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(train_df[train_df['Label']==1])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:45.668908Z","iopub.status.busy":"2024-05-19T12:48:45.668068Z","iopub.status.idle":"2024-05-19T12:48:45.690837Z","shell.execute_reply":"2024-05-19T12:48:45.689695Z","shell.execute_reply.started":"2024-05-19T12:48:45.668857Z"},"trusted":true},"outputs":[],"source":["train_dataset = Dataset.from_pandas(train_df)\n","val_dataset = Dataset.from_pandas(val_df)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:46.989119Z","iopub.status.busy":"2024-05-19T12:48:46.988730Z","iopub.status.idle":"2024-05-19T12:48:46.993823Z","shell.execute_reply":"2024-05-19T12:48:46.992782Z","shell.execute_reply.started":"2024-05-19T12:48:46.989089Z"},"trusted":true},"outputs":[],"source":["dataset_dict = DatasetDict({\n","    'train': train_dataset,\n","    'validation': val_dataset\n","})"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:48:49.010844Z","iopub.status.busy":"2024-05-19T12:48:49.010098Z","iopub.status.idle":"2024-05-19T12:48:49.723560Z","shell.execute_reply":"2024-05-19T12:48:49.722520Z","shell.execute_reply.started":"2024-05-19T12:48:49.010811Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading tokenizer_config.json: 100%|██████████| 341/341 [00:00<00:00, 64.0kB/s]\n","c:\\Users\\tanni\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanni\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n","Downloading config.json: 100%|██████████| 632/632 [00:00<00:00, 90.0kB/s]\n","Downloading vocab.txt: 100%|██████████| 241k/241k [00:00<00:00, 1.94MB/s]\n","Downloading tokenizer.json: 100%|██████████| 468k/468k [00:00<00:00, 5.57MB/s]\n","Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 12.2kB/s]\n","                                                                     \r"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny\")\n","\n","def tokenize_function(example):\n","    return tokenizer(example[\"Text\"], padding=\"max_length\", truncation=True, max_length=512)\n","\n","tokenized_datasets = dataset_dict.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:46:25.443326Z","iopub.status.busy":"2024-05-19T12:46:25.442598Z","iopub.status.idle":"2024-05-19T12:46:25.451882Z","shell.execute_reply":"2024-05-19T12:46:25.450926Z","shell.execute_reply.started":"2024-05-19T12:46:25.443294Z"},"trusted":true},"outputs":[{"data":{"text/plain":["' Оглянись ― и увидишь наверно: в переулке такси тарахтят, за церковной оградой деревья над ребенком больным шелестят, '"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tokenized_datasets['train']['Text'][0]"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:49:11.138015Z","iopub.status.busy":"2024-05-19T12:49:11.137587Z","iopub.status.idle":"2024-05-19T12:49:11.291902Z","shell.execute_reply":"2024-05-19T12:49:11.290885Z","shell.execute_reply.started":"2024-05-19T12:49:11.137985Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                      \r"]}],"source":["def preprocess_labels(example):\n","    example['Label'] = int(example['Label'])\n","    return example\n","\n","tokenized_datasets = tokenized_datasets.map(preprocess_labels)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:49:22.238355Z","iopub.status.busy":"2024-05-19T12:49:22.237698Z","iopub.status.idle":"2024-05-19T12:49:22.927048Z","shell.execute_reply":"2024-05-19T12:49:22.926185Z","shell.execute_reply.started":"2024-05-19T12:49:22.238322Z"},"trusted":true},"outputs":[],"source":["def convert_to_tensors(dataset):\n","    input_ids = torch.tensor(dataset['input_ids'])\n","    attention_mask = torch.tensor(dataset['attention_mask'])\n","    labels = torch.tensor(dataset['Label'])\n","    return input_ids, attention_mask, labels\n","\n","train_input_ids, train_attention_mask, train_labels = convert_to_tensors(tokenized_datasets['train'])\n","val_input_ids, val_attention_mask, val_labels = convert_to_tensors(tokenized_datasets['validation'])"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:50:28.237830Z","iopub.status.busy":"2024-05-19T12:50:28.237076Z","iopub.status.idle":"2024-05-19T12:50:28.502803Z","shell.execute_reply":"2024-05-19T12:50:28.501995Z","shell.execute_reply.started":"2024-05-19T12:50:28.237798Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading model.safetensors: 100%|██████████| 47.7M/47.7M [00:06<00:00, 7.72MB/s]\n","Some weights of the model checkpoint at cointegrated/rubert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"cointegrated/rubert-tiny\", num_labels=2)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:51:11.820482Z","iopub.status.busy":"2024-05-19T12:51:11.819814Z","iopub.status.idle":"2024-05-19T12:51:11.832551Z","shell.execute_reply":"2024-05-19T12:51:11.831444Z","shell.execute_reply.started":"2024-05-19T12:51:11.820450Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\tanni\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\transformers\\optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}],"source":["device = 'cuda'\n","model.to(device)\n","\n","# Определяем оптимизатор\n","optimizer = AdamW(model.parameters(), lr=2e-5)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T12:51:20.243323Z","iopub.status.busy":"2024-05-19T12:51:20.242540Z","iopub.status.idle":"2024-05-19T12:51:20.247667Z","shell.execute_reply":"2024-05-19T12:51:20.246680Z","shell.execute_reply.started":"2024-05-19T12:51:20.243291Z"},"trusted":true},"outputs":[],"source":["output_dir = \"./results\"\n","os.makedirs(output_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:07:21.478003Z","iopub.status.busy":"2024-05-19T13:07:21.477210Z","iopub.status.idle":"2024-05-19T13:07:21.483086Z","shell.execute_reply":"2024-05-19T13:07:21.482131Z","shell.execute_reply.started":"2024-05-19T13:07:21.477969Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(preds, labels):\n","    preds = np.argmax(preds, axis=1)\n","    accuracy = accuracy_score(labels, preds)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n","    return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:14:06.827282Z","iopub.status.busy":"2024-05-19T13:14:06.826571Z","iopub.status.idle":"2024-05-19T13:14:07.559260Z","shell.execute_reply":"2024-05-19T13:14:07.557704Z","shell.execute_reply.started":"2024-05-19T13:14:06.827250Z"},"trusted":true},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(29564, 312, padding_idx=0)\n","      (position_embeddings): Embedding(512, 312)\n","      (token_type_embeddings): Embedding(2, 312)\n","      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=312, out_features=312, bias=True)\n","              (key): Linear(in_features=312, out_features=312, bias=True)\n","              (value): Linear(in_features=312, out_features=312, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=312, out_features=312, bias=True)\n","              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=312, out_features=600, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=600, out_features=312, bias=True)\n","            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=312, out_features=312, bias=True)\n","              (key): Linear(in_features=312, out_features=312, bias=True)\n","              (value): Linear(in_features=312, out_features=312, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=312, out_features=312, bias=True)\n","              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=312, out_features=600, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=600, out_features=312, bias=True)\n","            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=312, out_features=312, bias=True)\n","              (key): Linear(in_features=312, out_features=312, bias=True)\n","              (value): Linear(in_features=312, out_features=312, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=312, out_features=312, bias=True)\n","              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=312, out_features=600, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=600, out_features=312, bias=True)\n","            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=312, out_features=312, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ОБЦИЛА НЕСКОЛЬКО ЭПОХ + ПРОВЕРИЛА НА OOS ВЫБОРКЕ, ОСТАНОВИЛАСЬ НА 3 ЭПОХЕ. В ДАЛЬНЕЙШЕМ ИСПОЛЬЗУЕТСЯ ОНА."]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-19T13:07:22.245039Z","iopub.status.busy":"2024-05-19T13:07:22.244687Z","iopub.status.idle":"2024-05-19T13:13:54.754128Z","shell.execute_reply":"2024-05-19T13:13:54.752902Z","shell.execute_reply.started":"2024-05-19T13:07:22.245015Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [37:37<00:00, 19.72it/s]\n"," 10%|█         | 1/10 [39:29<5:55:26, 2369.58s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","Train Loss: 0.4961, Accuracy: 0.7460, Precision: 0.7621, Recall: 0.7460, F1: 0.7419\n","Val Loss: 0.4753, Accuracy: 0.7592, Precision: 0.7921, Recall: 0.7592, F1: 0.7520\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [37:16<00:00, 19.90it/s]\n"," 20%|██        | 2/10 [1:18:34<5:13:59, 2354.99s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/10\n","Train Loss: 0.4584, Accuracy: 0.7730, Precision: 0.7856, Recall: 0.7730, F1: 0.7704\n","Val Loss: 0.4729, Accuracy: 0.7676, Precision: 0.7925, Recall: 0.7676, F1: 0.7624\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [37:53<00:00, 19.58it/s]\n"," 30%|███       | 3/10 [1:58:19<4:36:21, 2368.76s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/10\n","Train Loss: 0.4281, Accuracy: 0.7945, Precision: 0.8044, Recall: 0.7945, F1: 0.7927\n","Val Loss: 0.4789, Accuracy: 0.7687, Precision: 0.7960, Recall: 0.7687, F1: 0.7631\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [38:10<00:00, 19.43it/s]\n"," 40%|████      | 4/10 [2:38:22<3:58:13, 2382.22s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/10\n","Train Loss: 0.4008, Accuracy: 0.8124, Precision: 0.8198, Recall: 0.8124, F1: 0.8113\n","Val Loss: 0.4956, Accuracy: 0.7685, Precision: 0.7836, Recall: 0.7685, F1: 0.7653\n"]},{"name":"stderr","output_type":"stream","text":[" 57%|█████▋    | 25344/44519 [24:10<18:17, 17.48it/s]\n"," 40%|████      | 4/10 [3:02:32<4:33:48, 2738.12s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17880\\2273440199.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\tanni\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\tanni\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 10\n","batch_size = 4\n","\n","for epoch in trange(num_epochs):\n","    # Обучение\n","    model.train()\n","    total_loss = 0\n","    total_preds, total_labels = [], []\n","\n","    for i in trange(0, len(train_input_ids), batch_size):\n","        input_ids_batch = train_input_ids[i:i+batch_size].to(device)\n","        attention_mask_batch = train_attention_mask[i:i+batch_size].to(device)\n","        labels_batch = train_labels[i:i+batch_size].to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch, labels=labels_batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        logits = outputs.logits.detach().cpu().numpy()\n","        label_ids = labels_batch.cpu().numpy()\n","        total_preds.append(logits)\n","        total_labels.append(label_ids)\n","    \n","    avg_train_loss = total_loss / (len(train_input_ids) / batch_size)\n","    total_preds = np.concatenate(total_preds, axis=0)\n","    total_labels = np.concatenate(total_labels, axis=0)\n","    train_accuracy, train_precision, train_recall, train_f1 = compute_metrics(total_preds, total_labels)\n","\n","    # Валидация\n","    model.eval()\n","    total_val_loss = 0\n","    total_val_preds, total_val_labels = [], []\n","\n","    with torch.no_grad():\n","        for i in range(0, len(val_input_ids), batch_size):\n","            input_ids_batch = val_input_ids[i:i+batch_size].to(device)\n","            attention_mask_batch = val_attention_mask[i:i+batch_size].to(device)\n","            labels_batch = val_labels[i:i+batch_size].to(device)\n","            \n","            outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch, labels=labels_batch)\n","            loss = outputs.loss\n","            \n","            total_val_loss += loss.item()\n","            logits = outputs.logits.detach().cpu().numpy()\n","            label_ids = labels_batch.cpu().numpy()\n","            total_val_preds.append(logits)\n","            total_val_labels.append(label_ids)\n","    \n","    avg_val_loss = total_val_loss / (len(val_input_ids) / batch_size)\n","    total_val_preds = np.concatenate(total_val_preds, axis=0)\n","    total_val_labels = np.concatenate(total_val_labels, axis=0)\n","    val_accuracy, val_precision, val_recall, val_f1 = compute_metrics(total_val_preds, total_val_labels)\n","\n","    # Сохранение модели после каждой эпохи\n","    model.save_pretrained(f\"{output_dir}/model_epoch_{epoch + 1}\")\n","    tokenizer.save_pretrained(f\"{output_dir}/model_epoch_{epoch + 1}\")\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    print(f\"Train Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n","    print(f\"Val Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [45:19<00:00, 16.37it/s]\n"," 20%|██        | 1/5 [47:27<3:09:48, 2847.04s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/10\n","Train Loss: 0.3566, Accuracy: 0.8381, Precision: 0.8428, Recall: 0.8381, F1: 0.8376\n","Val Loss: 0.5057, Accuracy: 0.7682, Precision: 0.7912, Recall: 0.7682, F1: 0.7635\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [38:10<00:00, 19.44it/s]\n"," 40%|████      | 2/5 [1:27:36<2:09:29, 2589.67s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/10\n","Train Loss: 0.3319, Accuracy: 0.8518, Precision: 0.8553, Recall: 0.8518, F1: 0.8514\n","Val Loss: 0.5373, Accuracy: 0.7635, Precision: 0.7790, Recall: 0.7635, F1: 0.7601\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 44519/44519 [38:59<00:00, 19.03it/s]\n"," 60%|██████    | 3/5 [2:08:28<1:24:13, 2526.78s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/10\n","Train Loss: 0.3074, Accuracy: 0.8658, Precision: 0.8682, Recall: 0.8658, F1: 0.8655\n","Val Loss: 0.5458, Accuracy: 0.7613, Precision: 0.7725, Recall: 0.7613, F1: 0.7587\n"]},{"name":"stderr","output_type":"stream","text":[" 84%|████████▎ | 37211/44519 [39:26<07:44, 15.72it/s]\n"," 60%|██████    | 3/5 [2:47:55<1:51:56, 3358.46s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17880\\1171224676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mlabel_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 10\n","batch_size = 4\n","\n","for epoch in trange(5, num_epochs):\n","    # Обучение\n","    model.train()\n","    total_loss = 0\n","    total_preds, total_labels = [], []\n","\n","    for i in trange(0, len(train_input_ids), batch_size):\n","        input_ids_batch = train_input_ids[i:i+batch_size].to(device)\n","        attention_mask_batch = train_attention_mask[i:i+batch_size].to(device)\n","        labels_batch = train_labels[i:i+batch_size].to(device)\n","        \n","        optimizer.zero_grad()\n","        \n","        outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch, labels=labels_batch)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        \n","        total_loss += loss.item()\n","        logits = outputs.logits.detach().cpu().numpy()\n","        label_ids = labels_batch.cpu().numpy()\n","        total_preds.append(logits)\n","        total_labels.append(label_ids)\n","    \n","    avg_train_loss = total_loss / (len(train_input_ids) / batch_size)\n","    total_preds = np.concatenate(total_preds, axis=0)\n","    total_labels = np.concatenate(total_labels, axis=0)\n","    train_accuracy, train_precision, train_recall, train_f1 = compute_metrics(total_preds, total_labels)\n","\n","    # Валидация\n","    model.eval()\n","    total_val_loss = 0\n","    total_val_preds, total_val_labels = [], []\n","\n","    with torch.no_grad():\n","        for i in range(0, len(val_input_ids), batch_size):\n","            input_ids_batch = val_input_ids[i:i+batch_size].to(device)\n","            attention_mask_batch = val_attention_mask[i:i+batch_size].to(device)\n","            labels_batch = val_labels[i:i+batch_size].to(device)\n","            \n","            outputs = model(input_ids=input_ids_batch, attention_mask=attention_mask_batch, labels=labels_batch)\n","            loss = outputs.loss\n","            \n","            total_val_loss += loss.item()\n","            logits = outputs.logits.detach().cpu().numpy()\n","            label_ids = labels_batch.cpu().numpy()\n","            total_val_preds.append(logits)\n","            total_val_labels.append(label_ids)\n","    \n","    avg_val_loss = total_val_loss / (len(val_input_ids) / batch_size)\n","    total_val_preds = np.concatenate(total_val_preds, axis=0)\n","    total_val_labels = np.concatenate(total_val_labels, axis=0)\n","    val_accuracy, val_precision, val_recall, val_f1 = compute_metrics(total_val_preds, total_val_labels)\n","\n","    # Сохранение модели после каждой эпохи\n","    model.save_pretrained(f\"{output_dir}/model_epoch_{epoch + 1}\")\n","    tokenizer.save_pretrained(f\"{output_dir}/model_epoch_{epoch + 1}\")\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    print(f\"Train Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}\")\n","    print(f\"Val Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5041350,"sourceId":8458053,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":4}
